{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"h_xtj2SRAgzH"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7mB1bhOL5N8m"},"outputs":[],"source":["## 라이브러리 불러오기\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import h5py\n","import scipy.io\n","import os\n","import glob, itertools\n","import argparse, random\n","\n","import torch\n","from torch import nn, optim\n","import torchvision\n","from torchvision import transforms, datasets, models, utils\n","from torch.autograd import Variable\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.utils import save_image, make_grid\n","from PIL import Image\n","from sklearn.model_selection import train_test_split\n","from torch.nn import functional as F\n","from skimage import io, transform\n","from torch.optim import lr_scheduler\n","from skimage.transform import AffineTransform, warp\n","from tqdm import tqdm_notebook as tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TNKzowO05N8n"},"outputs":[],"source":["## 파라미터 정의하기\n","# number of epochs of training\n","n_epochs = 20\n","# size of the batches\n","batch_size = 16\n","# adam: learning rate\n","lr = 0.00008\n","# adam: decay of first order momentum of gradient\n","b1 = 0.5\n","# adam: decay of second order momentum of gradient\n","b2 = 0.999\n","\n","cuda = torch.cuda.is_available()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S8Z-oHyF5N8n","outputId":"b1c7ee33-7519-442b-b4f2-4dc0e03919ca"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training Data: 7000\n","Testing Data: 7000\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\Femur\\.conda\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:3: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n","  This is separate from the ipykernel package so we can avoid doing imports until\n","C:\\Users\\Femur\\.conda\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:11: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n","  # This is added back by InteractiveShellApp.init_path()\n"]}],"source":["## 데이터 가져오기\n","# Training data\n","file_train = h5py.File(f'/content/drive/MyDrive/산학협동강좌/AItopopt/Train_data.hdf5')\n","iters_train = file_train['iters'][:]\n","targets_train = file_train['targets'][:]\n","datanum = iters_train.shape[0]\n","print(f\"Training Data: {datanum}\")\n","\n","\n","#Test data\n","file_test = h5py.File(f'/content/drive/MyDrive/산학협동강좌/AItopopt/Test_data.hdf5')\n","iters_test = file_test['iters'][:]\n","targets_test = file_test['targets'][:]\n","datanum = targets_train.shape[0]\n","print(f\"Testing Data: {datanum}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eKjyTu485N8n"},"outputs":[],"source":["## Dataset 만들기\n","class MyData(Dataset):\n","    def __init__(self, train, transform = None):\n","        if train == True:\n","            self.x = iters_train\n","            self.y = targets_train\n","        else:\n","            self.x = iters_test\n","            self.y = targets_test\n","\n","        #Applying transformation\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.x)\n","\n","    def __getitem__(self, idx):\n","        image_iters = np.moveaxis(self.x[idx], -1, 0).astype('float')\n","        image_targets = np.moveaxis(self.y[idx], -1, 0).astype('float')\n","        sample={'iters': image_iters, 'targets': image_targets}\n","\n","        #Applying transformation\n","        if self.transform:\n","            sample=self.transform(sample)\n","\n","        return sample"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"71UqoZXv5N8o"},"outputs":[],"source":["## 텐서로 변환하기\n","class ToTensor(object):\n","    def __call__(self, sample):\n","        image_iters, image_targets = sample['iters'], sample['targets']\n","\n","        image_iters=torch.from_numpy(image_iters)\n","        image_targets=torch.from_numpy(image_targets)\n","\n","        return {'iters': image_iters, 'targets': image_targets}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hqdkEHwV5N8o"},"outputs":[],"source":["## DataLoader로 학습용 데이터 준비하기\n","transformed_train_data = MyData(train=True, transform=transforms.Compose([ToTensor()]))\n","transformed_test_data = MyData(train=False, transform=transforms.Compose([ToTensor()]))\n","train_dataloader = DataLoader(transformed_train_data, batch_size=16, shuffle=True, num_workers=0)\n","test_dataloader = DataLoader(transformed_test_data, batch_size=16, shuffle=True, num_workers=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Eyrklvm35N8o"},"outputs":[],"source":["## 네트워크 구축하기\n","class DoubleConv(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, padding=1)\n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","        self.relu1 = nn.ReLU(inplace=True)\n","        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","        self.relu2 = nn.ReLU(inplace=True)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu1(x)\n","        x = self.conv2(x)\n","        x = self.bn2(x)\n","        x = self.relu2(x)\n","        return x\n","\n","class UNet(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(UNet, self).__init__()\n","        self.encoder_conv1 = DoubleConv(in_channels, 64)\n","        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.encoder_conv2 = DoubleConv(64, 128)\n","        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.encoder_conv3 = DoubleConv(128, 256)\n","        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.encoder_conv4 = DoubleConv(256, 512)\n","        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.encoder_conv5 = DoubleConv(512, 1024)\n","\n","        self.upconv6 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n","        self.decoder_conv6 = DoubleConv(1024, 512)\n","        self.upconv7 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n","        self.decoder_conv7 = DoubleConv(512, 256)\n","        self.upconv8 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n","        self.decoder_conv8 = DoubleConv(256, 128)\n","        self.upconv9 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n","        self.decoder_conv9 = DoubleConv(128, 64)\n","\n","        self.final_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n","\n","    def forward(self, x):\n","        x1 = self.encoder_conv1(x)\n","        x2 = self.encoder_conv2(self.pool1(x1))\n","        x3 = self.encoder_conv3(self.pool2(x2))\n","        x4 = self.encoder_conv4(self.pool3(x3))\n","        x5 = self.encoder_conv5(self.pool4(x4))\n","\n","        x = self.upconv6(x5)\n","        x = torch.cat([x, x4], dim=1)\n","        x = self.decoder_conv6(x)\n","        x = self.upconv7(x)\n","        x = torch.cat([x, x3], dim=1)\n","        x = self.decoder_conv7(x)\n","        x = self.upconv8(x)\n","        x = torch.cat([x, x2], dim=1)\n","        x = self.decoder_conv8(x)\n","        x = self.upconv9(x)\n","        x = torch.cat([x, x1], dim=1)\n","        x = self.decoder_conv9(x)\n","\n","        x = self.final_conv(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CsCdCd1B5N8o"},"outputs":[],"source":["## 손실함수 및 옵티마이저\n","# Initialize generator and discriminator\n","generator = UNet(1,1)\n","\n","# Loss function\n","fn_loss = torch.nn.L1Loss()\n","\n","if cuda:\n","    generator = generator.cuda()\n","    fn_loss = fn_loss.cuda()\n","\n","# Optimizers\n","optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(b1, b2))\n","\n","Tensor = torch.cuda.FloatTensor if cuda else torch.Tensor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A98vvavC5N8p","outputId":"d39a85a3-f00e-46ac-bc9b-2814073ae7b0","colab":{"referenced_widgets":["0b82ad92005e4c5f833aa6e8b371b6f0"]}},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\Femur\\.conda\\envs\\pytorch\\lib\\site-packages\\ipykernel_launcher.py:11: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n","Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n","  # This is added back by InteractiveShellApp.init_path()\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"0b82ad92005e4c5f833aa6e8b371b6f0","version_major":2,"version_minor":0},"text/plain":["HBox(children=(HTML(value='Training Epoch 0 '), FloatProgress(value=0.0, max=438.0), HTML(value='')))"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["\n"]},{"ename":"RuntimeError","evalue":"cuDNN error: CUDNN_STATUS_NOT_INITIALIZED","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[1;32m<ipython-input-9-d7e0443d33cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;31m# loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mloss_G\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgen_opt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgs_targets\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[0mloss_G\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[0moptimizer_G\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[1;32m--> 221\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32m~\\.conda\\envs\\pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mRuntimeError\u001b[0m: cuDNN error: CUDNN_STATUS_NOT_INITIALIZED"]}],"source":["## 네트워크 학습하기\n","\n","train_gen_losses, train_disc_losses, train_counter = [], [], []\n","test_gen_losses, test_disc_losses = [], []\n","test_counter = [idx*len(train_dataloader.dataset) for idx in range(1, n_epochs+1)]\n","\n","for epoch in range(n_epochs):\n","\n","    ### Training\n","    gen_loss = 0\n","    tqdm_bar = tqdm(train_dataloader, desc=f'Training Epoch {epoch} ', total=int(len(train_dataloader)))\n","    for batch_idx, imgs in enumerate(tqdm_bar):\n","        generator.train()\n","        # Configure model input\n","        imgs_iters = Variable(imgs[\"iters\"].type(Tensor))\n","        imgs_targets = Variable(imgs[\"targets\"].type(Tensor))\n","        ### Train Generator\n","        optimizer_G.zero_grad()\n","        # Generate (near) optimal images from input\n","        gen_opt = generator(imgs_iters)\n","        # loss\n","        loss_G = fn_loss(gen_opt, imgs_targets)\n","        loss_G.backward()\n","        optimizer_G.step()\n","\n","        gen_loss += loss_G.item()\n","        train_gen_losses.append(loss_G.item())\n","        train_counter.append(batch_idx*batch_size + imgs_iters.size(0) + epoch*len(train_dataloader.dataset))\n","        tqdm_bar.set_postfix(gen_loss=gen_loss/(batch_idx+1))\n","\n","    # Testing\n","    gen_loss = 0\n","    tqdm_bar = tqdm(test_dataloader, desc=f'Testing Epoch {epoch} ', total=int(len(test_dataloader)))\n","    for batch_idx, imgs in enumerate(tqdm_bar):\n","        generator.eval()\n","        # Configure model input\n","        imgs_iters = Variable(imgs[\"iters\"].type(Tensor))\n","        imgs_targets = Variable(imgs[\"targets\"].type(Tensor))\n","        ### Eval Generator\n","        # Generate (near) optimal images from input\n","        gen_opt = generator(imgs_iters)\n","        # loss\n","        loss_G = fn_loss(gen_opt, imgs_targets)\n","\n","        gen_loss += loss_G.item()\n","        tqdm_bar.set_postfix(gen_loss=gen_loss/(batch_idx+1))\n","\n","    test_gen_losses.append(gen_loss/len(test_dataloader))\n","\n","    # Save model checkpoints\n","    if np.argmin(test_gen_losses) == len(test_gen_losses)-1:\n","        torch.save(generator.state_dict(), \"generator_opt.pth\")"]}],"metadata":{"kernelspec":{"display_name":"pytorch","language":"python","name":"pytorch"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}