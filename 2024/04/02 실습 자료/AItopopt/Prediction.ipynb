{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6OCh2B4Lh5WA","executionInfo":{"status":"ok","timestamp":1708391821659,"user_tz":-540,"elapsed":20236,"user":{"displayName":"고혁진","userId":"02894236210669937770"}},"outputId":"eecbee42-e55c-4a02-a0df-913aecb91fe3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D1hFJ1ip6KOz"},"outputs":[],"source":["## 라이브러리 불러오기\n","import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import h5py\n","import scipy.io\n","import os\n","import glob, itertools\n","import argparse, random\n","\n","import torch\n","from torch import nn, optim\n","import torchvision\n","from torchvision import transforms, datasets, models, utils\n","from torch.autograd import Variable\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision.utils import save_image, make_grid\n","from PIL import Image\n","from sklearn.model_selection import train_test_split\n","from torch.nn import functional as F\n","from skimage import io, transform\n","from torch.optim import lr_scheduler\n","from skimage.transform import AffineTransform, warp\n","from tqdm import tqdm_notebook as tqdm"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-fW9luP56KO2"},"outputs":[],"source":["## 파라미터 정의하기\n","# load pretrained models\n","load_pretrained_models = True\n","# number of epochs of training\n","n_epochs = 11\n","# size of the batches\n","batch_size = 16\n","# adam: learning rate\n","lr = 0.00008\n","# adam: decay of first order momentum of gradient\n","b1 = 0.5\n","# adam: decay of second order momentum of gradient\n","b2 = 0.999\n","# epoch from which to start lr decay\n","decay_epoch = 100\n","\n","cuda = torch.cuda.is_available()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XcvOOHnv6KO2"},"outputs":[],"source":["## 데이터 가져오기\n","#Test data\n","file_test = h5py.File(f'/content/drive/MyDrive/산학협동강좌/AItopopt/Test_data_sub.hdf5')\n","iters_test = file_test['iters'][:]\n","targets_test = file_test['targets'][:]\n","datanum = targets_test.shape[0]\n","print(f\"Testing Data: {datanum}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k0nFeMgV6KO3"},"outputs":[],"source":["## Dataset 만들기\n","class MyData(Dataset):\n","    def __init__(self, train, transform = None):\n","        if train == True:\n","            self.x = iters_train\n","            self.y = targets_train\n","        else:\n","            self.x = iters_test\n","            self.y = targets_test\n","\n","        #Applying transformation\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.x)\n","\n","    def __getitem__(self, idx):\n","        image_iters = np.moveaxis(self.x[idx], -1, 0).astype('float')\n","        image_targets = np.moveaxis(self.y[idx], -1, 0).astype('float')\n","        sample={'iters': image_iters, 'targets': image_targets}\n","\n","        #Applying transformation\n","        if self.transform:\n","            sample=self.transform(sample)\n","\n","        return sample"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E3ohw5oY6KO3"},"outputs":[],"source":["## 텐서로 변환하기\n","class ToTensor(object):\n","    def __call__(self, sample):\n","        image_iters, image_targets = sample['iters'], sample['targets']\n","\n","        image_iters=torch.from_numpy(image_iters)\n","        image_targets=torch.from_numpy(image_targets)\n","\n","        return {'iters': image_iters, 'targets': image_targets}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M7qtaWJx6KO3"},"outputs":[],"source":["## DataLoader로 테스트 데이터 준비하기\n","transformed_test_data = MyData(train=False, transform=transforms.Compose([ToTensor()]))\n","test_dataloader = DataLoader(transformed_test_data, batch_size=16, shuffle=True, num_workers=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gkM6RBBK6KO3"},"outputs":[],"source":["## 네트워크 구축하기\n","class DoubleConv(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super().__init__()\n","        self.conv1 = nn.Conv2d(in_channels, out_channels, 3, padding=1)\n","        self.bn1 = nn.BatchNorm2d(out_channels)\n","        self.relu1 = nn.ReLU(inplace=True)\n","        self.conv2 = nn.Conv2d(out_channels, out_channels, 3, padding=1)\n","        self.bn2 = nn.BatchNorm2d(out_channels)\n","        self.relu2 = nn.ReLU(inplace=True)\n","\n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.bn1(x)\n","        x = self.relu1(x)\n","        x = self.conv2(x)\n","        x = self.bn2(x)\n","        x = self.relu2(x)\n","        return x\n","\n","class UNet(nn.Module):\n","    def __init__(self, in_channels, out_channels):\n","        super(UNet, self).__init__()\n","        self.encoder_conv1 = DoubleConv(in_channels, 64)\n","        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.encoder_conv2 = DoubleConv(64, 128)\n","        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.encoder_conv3 = DoubleConv(128, 256)\n","        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.encoder_conv4 = DoubleConv(256, 512)\n","        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.encoder_conv5 = DoubleConv(512, 1024)\n","\n","        self.upconv6 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n","        self.decoder_conv6 = DoubleConv(1024, 512)\n","        self.upconv7 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n","        self.decoder_conv7 = DoubleConv(512, 256)\n","        self.upconv8 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n","        self.decoder_conv8 = DoubleConv(256, 128)\n","        self.upconv9 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n","        self.decoder_conv9 = DoubleConv(128, 64)\n","\n","        self.final_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n","\n","    def forward(self, x):\n","        x1 = self.encoder_conv1(x)\n","        x2 = self.encoder_conv2(self.pool1(x1))\n","        x3 = self.encoder_conv3(self.pool2(x2))\n","        x4 = self.encoder_conv4(self.pool3(x3))\n","        x5 = self.encoder_conv5(self.pool4(x4))\n","\n","        x = self.upconv6(x5)\n","        x = torch.cat([x, x4], dim=1)\n","        x = self.decoder_conv6(x)\n","        x = self.upconv7(x)\n","        x = torch.cat([x, x3], dim=1)\n","        x = self.decoder_conv7(x)\n","        x = self.upconv8(x)\n","        x = torch.cat([x, x2], dim=1)\n","        x = self.decoder_conv8(x)\n","        x = self.upconv9(x)\n","        x = torch.cat([x, x1], dim=1)\n","        x = self.decoder_conv9(x)\n","\n","        x = self.final_conv(x)\n","        return x"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_pjZPkpl6KO4"},"outputs":[],"source":["## 학습된 네트워크 불러오기\n","\n","generator = UNet(1,1)\n","generator.load_state_dict(torch.load(\"/content/drive/MyDrive/산학협동강좌/AItopopt/generator_opt.pth\", map_location=torch.device('cpu')))\n","generator.eval()\n","\n","if cuda:\n","    generator = generator.cuda()\n","\n","Tensor = torch.cuda.FloatTensor if cuda else torch.Tensor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ONOJud8f6KO4"},"outputs":[],"source":["## 예측 이미지 생성하고 저장하기\n","gen_loss = 0\n","tqdm_bar = tqdm(test_dataloader, desc=f'Predict optimal images', total=int(len(test_dataloader)))\n","for batch_idx, imgs in enumerate(tqdm_bar):\n","    # Configure model input\n","    imgs_iters = Variable(imgs[\"iters\"].type(Tensor))\n","    imgs_targets = Variable(imgs[\"targets\"].type(Tensor))\n","    # Generate a (near) optimal image from input\n","    gen_opt = generator(imgs_iters)\n","    imgs_iters = make_grid(imgs_iters, nrow=1, padding=10, pad_value=1)\n","    imgs_targets = make_grid(imgs_targets, nrow=1, padding=10, pad_value=1)\n","    gen_opt = make_grid(gen_opt, nrow=1, padding=10, pad_value=1)\n","    img_grid = torch.cat((imgs_iters, gen_opt,imgs_targets), -1)\n","    save_image(img_grid, f\"/content/drive/MyDrive/산학협동강좌/AItopopt/predict_images/{batch_idx}.png\", normalize=False)"]}],"metadata":{"kernelspec":{"display_name":"pytorch","language":"python","name":"pytorch"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}